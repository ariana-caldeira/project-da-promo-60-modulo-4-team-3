# üìä An√°lisis de la serie *The Simpsons*

## Predicciones, cronovinculaci√≥n y geograf√≠a del or√°culo

---

## üìå Descripci√≥n del proyecto

Este proyecto analiza el fen√≥meno cultural de las denominadas **predicciones de *The Simpsons***, explorando la relaci√≥n temporal, tem√°tica y geogr√°fica entre eventos representados en la serie y sucesos reales ocurridos posteriormente.

El an√°lisis se apoya en un dataset estructurado y normalizado que documenta coincidencias entre ficci√≥n y realidad. El objetivo es identificar patrones temporales, categor√≠as dominantes, personajes implicados y la distribuci√≥n geogr√°fica de estas predicciones, culminando en la creaci√≥n de visualizaciones interactivas en **Tableau**.

---

## üéØ Objetivos del an√°lisis

* **Cuantificar la cronovinculaci√≥n**
  Evaluar el grado de acierto entre la ficci√≥n y la realidad analizando el tiempo transcurrido entre la emisi√≥n del episodio y el evento real.

* **Mapear la geograf√≠a del or√°culo**
  Analizar la dimensi√≥n global de las predicciones mediante la identificaci√≥n de regiones y pa√≠ses con mayor densidad de coincidencias.

* **Perfilado de portavoces prof√©ticos**
  Identificar qu√© personajes de la serie act√∫an como principales conductores de estas visiones del futuro.

* **Taxonom√≠a de aciertos**
  Clasificar las predicciones por categor√≠as tem√°ticas (Pol√≠tica, Tecnolog√≠a, Sociedad, etc.) para detectar en qu√© √°reas la serie resulta m√°s visionaria.

* **Ingenier√≠a de datos para visualizaci√≥n**
  Normalizar y optimizar un dataset complejo, resolviendo conflictos de geolocalizaci√≥n y formato, para su explotaci√≥n interactiva en Tableau.

---

## ‚ùì Preguntas de investigaci√≥n

* ¬øCu√°l es el **epicentro de profec√≠as**?
  ¬øQu√© pa√≠ses o regiones presentan una mayor densidad de predicciones cumplidas?

* ¬øQui√©n es el **personaje or√°culo**?
  ¬øQu√© personaje aparece con mayor frecuencia en predicciones de alto impacto o viralidad?

* ¬øCu√°l es la **brecha temporal del futuro**?
  ¬øCu√°ntos a√±os pasan, en promedio, entre la emisi√≥n del episodio y el evento real?

* ¬øQu√© **temas dominan la narrativa predictiva**?
  ¬øPredominan las predicciones tecnol√≥gicas sobre las pol√≠ticas y c√≥mo var√≠a esto seg√∫n el nivel de coincidencia?

* ¬øC√≥mo influye la **viralidad**?
  ¬øExiste relaci√≥n entre el nivel de coincidencia y el n√∫mero de visualizaciones (*views*)?

---

## üß† Metodolog√≠a

El proyecto se desarrolla siguiendo las siguientes fases:

1. **Exploraci√≥n inicial del dataset**

   * Revisi√≥n de estructura, tipos de datos y valores nulos.
   * Comprensi√≥n del esquema de columnas.

2. **Limpieza y normalizaci√≥n**

   * Unificaci√≥n de formatos de fecha.
   * Normalizaci√≥n de ubicaciones geogr√°ficas (pa√≠ses y regiones).
   * Estandarizaci√≥n de identificadores, categor√≠as y m√©tricas num√©ricas.

3. **Transformaci√≥n y enriquecimiento**

   * C√°lculo de m√©tricas temporales (diferencia de a√±os).
   * Creaci√≥n de campos auxiliares para an√°lisis geogr√°fico y tem√°tico.
   * Preparaci√≥n del dataset final para visualizaci√≥n.

4. **An√°lisis exploratorio (EDA)**

   * Distribuci√≥n temporal de las predicciones.
   * An√°lisis por categor√≠as, personajes y regiones.
   * Exploraci√≥n de relaciones entre coincidencia y viralidad.

5. **Visualizaci√≥n**

   * Exportaci√≥n del dataset limpio para Tableau.
   * Creaci√≥n de dashboards interactivos (mapas, rankings y gr√°ficos de dispersi√≥n).

---

## üìÅ Dataset

### Dataset principal

* **Archivo:** `the_simpson_predictions.csv`
* **Formato:** CSV

**Descripci√≥n:**
Dataset que documenta predicciones atribuidas a *The Simpsons*, vinculando eventos ficticios con sucesos reales ocurridos posteriormente. El archivo fue generado mediante un proceso h√≠brido de investigaci√≥n manual y estructuraci√≥n asistida por Inteligencia Artificial, y finalmente normalizado y exportado usando **Pandas**.

---

### üß± Estructura del dataset

| Columna                 | Descripci√≥n                          |
| ----------------------- | ------------------------------------ |
| ID                      | Identificador √∫nico de la predicci√≥n |
| EPISODIO                | T√≠tulo completo del episodio         |
| TEMPORADA               | N√∫mero de temporada                  |
| EPISODIO_NUM            | N√∫mero de episodio                   |
| FECHA_EMISION           | Fecha original de emisi√≥n            |
| A√ëO_EMISION             | A√±o de emisi√≥n                       |
| CATEGORIA               | Tema principal de la predicci√≥n      |
| UBICACION               | Lugar geogr√°fico asociado            |
| DESCRIPCION             | Descripci√≥n del evento en la serie   |
| PREDICCION              | Evento ocurrido en la vida real      |
| DIFERENCIA_A√ëOS         | A√±os entre emisi√≥n y evento real     |
| NIVEL_COINCIDENCIA      | Baja / Media / Alta                  |
| PERSONAJE *(si aplica)* | Personaje asociado                   |
| VIEWS *(si aplica)*     | M√©trica de impacto o viralidad       |

---

## üßπ Decisiones de limpieza y normalizaci√≥n

* Las decisiones de limpieza y normalizaci√≥n se basan en un proceso h√≠brido de an√°lisis humano y estructuraci√≥n asistida por IA.
* Se unificaron formatos de fecha (AAAA-MM-DD) y se estandarizaron identificadores y categor√≠as tem√°ticas.
* Las ubicaciones geogr√°ficas fueron normalizadas mediante correcciones manuales para garantizar consistencia internacional.
* Todo el proceso fue gestionado y validado en Python utilizando Pandas, asegurando la coherencia del dataset y su correcta explotaci√≥n anal√≠tica y visual.

---

## üõ†Ô∏è Tecnolog√≠as utilizadas

* **Python**
  * Pandas
  * NumPy
* **Jupyter Notebook**
  * An√°lisis exploratorio y preparaci√≥n de datos
* **Tableau Desktop / Tableau Public**
  * Visualizaci√≥n interactiva final
* **CSV**
  * Formato del dataset principal
* **Geocodificaci√≥n manual**
  * Correcci√≥n y estandarizaci√≥n de ubicaciones

---
## ‚úÖ Estado del proyecto

- [x] Definici√≥n del esquema de datos  
- [x] Creaci√≥n y normalizaci√≥n del dataset  
- [x] Cargar y explorar el dataset  
- [x] Analizar valores nulos y tipos de datos  
- [x] Limpiar y normalizar fechas y ubicaciones  
- [x] Crear m√©tricas temporales y categ√≥ricas  
- [x] Analizar distribuci√≥n por categor√≠as  
- [x] Analizar geograf√≠a de predicciones  
- [x] Analizar personajes y niveles de coincidencia  
- [x] Exportar dataset final para Tableau  
- [x] Documentar hallazgos y conclusiones  

---
## 7Ô∏è‚É£ C√≥digo de ejemplo (base)

```python
import pandas as pd

# Carga del dataset
df = pd.read_csv("the_simpson_predictions.csv")

# Visualizar primeras filas
df.head()

# -----------------------------
# Identificar y revisar valores nulos
# -----------------------------
filas_con_nulos = df.isnull().any(axis=1)
df_con_nulos = df[filas_con_nulos]
print("Filas con valores nulos:")
df_con_nulos

# -----------------------------
# Rellenar nulos simples
# -----------------------------
# Por ejemplo, trasladar TITLE a TITLE_EPISODES
if 'TITLE' in df.columns:
    df['TITLE_EPISODES'] = df['TITLE_EPISODES'].fillna(df['TITLE'])

# -----------------------------
# Reordenar columnas principales
# -----------------------------
nuevo_orden = [
    'ID', 'TITLE_EPISODES', 'SEASON_EPISODE_NUMERIC', 'NUMBER_IN_SEASON',
    'YEAR', 'PREDICTION CATEGORY', 'GEOGRAPHICAL LOCATION',
    'COINCIDENCE LEVEL', 'DIFFERENCE (YEARS)', 'DESCRIPTION', 'PREDICTION', 'VIEWS'
]
df = df[nuevo_orden].copy()

print("Columnas reordenadas con √©xito:")
print(list(df.columns))

---

## üìå Notas finales

Este repositorio documenta el proceso de an√°lisis y preparaci√≥n de datos.
Las visualizaciones finales y conclusiones se presentan en Tableau a partir del dataset limpio generado en este proyecto.
